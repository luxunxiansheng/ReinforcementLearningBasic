{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1599126920098",
   "display_name": "Python 3.7.6 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/ornot/workspace/ReinforcementLearningBasic/work\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from algorithm.value_based.tabular_solution_method.monte_carlo_method.monte_carlo_off_policy_evaluation import MonteCarloOffPolicyEvaluation\n",
    "from policy.policy import TabularPolicy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from env.blackjack import BlackjackEnv\n",
    "\n",
    "def test_mc_offpolicy_evaluation_method_for_blackjack():\n",
    "    env = BlackjackEnv()\n",
    "\n",
    "    q_table = env.build_Q_table()\n",
    "\n",
    "    # Random behavior policy\n",
    "    b_policy_table = env.build_policy_table()\n",
    "    b_policy = TabularPolicy(b_policy_table)\n",
    "\n",
    "    # spcific target policy only for blackjack\n",
    "    t_policy_table = env.build_policy_table()\n",
    "    for state_index, _ in t_policy_table.items():\n",
    "        card_sum = state_index[0]\n",
    "        if card_sum < 20:\n",
    "            t_policy_table[state_index][BlackjackEnv.HIT] = 1.0\n",
    "            t_policy_table[state_index][BlackjackEnv.STICK] = 0.0\n",
    "        else:\n",
    "            t_policy_table[state_index][BlackjackEnv.HIT] = 0.0\n",
    "            t_policy_table[state_index][BlackjackEnv.STICK] = 1.0\n",
    "    t_policy = TabularPolicy(t_policy_table)\n",
    "\n",
    "    error = {}\n",
    "    init_state = env.reset(False)\n",
    "    for episode in range(10000):\n",
    "        state_value = 0.0\n",
    "        for _ in range(100):\n",
    "            rl_method = MonteCarloOffPolicyEvaluation(q_table, b_policy, t_policy, env, episode)\n",
    "            current_q_value= rl_method.evaluate()\n",
    "            state_value = state_value + current_q_value[init_state][BlackjackEnv.HIT]+0.27726\n",
    "        error[episode] = state_value*state_value/100\n",
    "        print(\"{}:{:.3f}\".format(episode, error[episode]))\n",
    "    \n",
    "   "
   ]
  }
 ]
}